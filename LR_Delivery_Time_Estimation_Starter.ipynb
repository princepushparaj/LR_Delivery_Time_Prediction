{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uOZe3UO68U-"
   },
   "source": [
    "# Order Delivery Time Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qd9e2-HF6_85"
   },
   "source": [
    "## Objectives\n",
    "The objective of this assignment is to build a regression model that predicts the delivery time for orders placed through Porter. The model will use various features such as the items ordered, the restaurant location, the order protocol, and the availability of delivery partners.\n",
    "\n",
    "The key goals are:\n",
    "- Predict the delivery time for an order based on multiple input features\n",
    "- Improve delivery time predictions to optimiae operational efficiency\n",
    "- Understand the key factors influencing delivery time to enhance the model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcC6tJ2p7F2p"
   },
   "source": [
    "## Data Pipeline\n",
    "The data pipeline for this assignment will involve the following steps:\n",
    "1. **Data Loading**\n",
    "2. **Data Preprocessing and Feature Engineering**\n",
    "3. **Exploratory Data Analysis**\n",
    "4. **Model Building**\n",
    "5. **Model Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGOQI_f72jV1"
   },
   "source": [
    "## Data Understanding\n",
    "The dataset contains information on orders placed through Porter, with the following columns:\n",
    "\n",
    "| Field                     | Description                                                                                 |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------|\n",
    "| market_id                 | Integer ID representing the market where the restaurant is located.                         |\n",
    "| created_at                | Timestamp when the order was placed.                                                        |\n",
    "| actual_delivery_time      | Timestamp when the order was delivered.                                                     |\n",
    "| store_primary_category    | Category of the restaurant (e.g., fast food, dine-in).                                      |\n",
    "| order_protocol            | Integer representing how the order was placed (e.g., via Porter, call to restaurant, etc.). |\n",
    "| total_items               | Total number of items in the order.                                                         |\n",
    "| subtotal                  | Final price of the order.                                                                   |\n",
    "| num_distinct_items        | Number of distinct items in the order.                                                      |\n",
    "| min_item_price            | Price of the cheapest item in the order.                                                    |\n",
    "| max_item_price            | Price of the most expensive item in the order.                                              |\n",
    "| total_onshift_dashers     | Number of delivery partners on duty when the order was placed.                              |\n",
    "| total_busy_dashers        | Number of delivery partners already occupied with other orders.                             |\n",
    "| total_outstanding_orders  | Number of orders pending fulfillment at the time of the order.                              |\n",
    "| distance                  | Total distance from the restaurant to the customer.                                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QoCQFDzHUWP"
   },
   "source": [
    "## **Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jun9CeAc7QOw"
   },
   "outputs": [],
   "source": [
    "# Import essential libraries for data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MueJxkvUIII3"
   },
   "source": [
    "## **1. Loading the data**\n",
    "Load 'porter_data_1.csv' as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJS8ZRJXHTwv"
   },
   "outputs": [],
   "source": [
    "# Importing the file porter_data_1.csv\n",
    "df = pd.read_csv('porter_data_1.csv')\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSRQocOkMSQl"
   },
   "source": [
    "## **2. Data Preprocessing and Feature Engineering** <font color = red>[15 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02uPO8aQfLnn"
   },
   "source": [
    "#### **2.1 Fixing the Datatypes**  <font color = red>[5 marks]</font> <br>\n",
    "The current timestamps are in object format and need conversion to datetime format for easier handling and intended functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b22Kzjew3rdM"
   },
   "source": [
    "##### **2.1.1** <font color = red>[2 marks]</font> <br>\n",
    "Convert date and time fields to appropriate data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoGkz909IXjv"
   },
   "outputs": [],
   "source": [
    "# Convert 'created_at' and 'actual_delivery_time' columns to datetime format\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['actual_delivery_time'] = pd.to_datetime(df['actual_delivery_time'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1EBPjFc4Qca"
   },
   "source": [
    "##### **2.1.2**  <font color = red>[3 marks]</font> <br>\n",
    "Convert categorical fields to appropriate data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PihPSPhQq1nQ"
   },
   "outputs": [],
   "source": [
    "# Convert categorical features to category type\n",
    "df['store_primary_category'] = df['store_primary_category'].astype('category')\n",
    "df['order_protocol'] = df['order_protocol'].astype('category')\n",
    "df['market_id'] = df['market_id'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsEGroRFlX8z"
   },
   "source": [
    "#### **2.2 Feature Engineering** <font color = red>[5 marks]</font> <br>\n",
    "Calculate the time taken to execute the delivery as well as extract the hour and day at which the order was placed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2.0** <font color = red>[2 marks]</font> <br> (will change this later)\n",
    "`Handling Missing Values` - This was not mentioned in the pyinb but it was mentioned in the PDF. Thus adding here.\n",
    "\n",
    "This will show you which columns have missing values and how many.\n",
    "\n",
    "- Dropped rows with missing timestamps (`created_at`, `actual_delivery_time`) as they are essential for the target variable.\n",
    "- For numerical features, imputed missing values using the median to reduce sensitivity to outliers.\n",
    "- For categorical features, imputed using the mode (most frequent category)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2.0.1 Check for Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_summary = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_summary[missing_summary > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2.0.2 Understand the Impact**\n",
    "Inspect rows with missing values in case you want to drop or impute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values\n",
    "(df.isnull().mean() * 100).round(2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.2.0.3 Handle Missing Data (Common Strategy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing target values (if any)\n",
    "df = df.dropna(subset=['actual_delivery_time', 'created_at'])\n",
    "\n",
    "# For numeric columns, fill with median\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "cat_cols = df.select_dtypes(include='category').columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BubGzQyJpHLQ"
   },
   "source": [
    "##### **2.2.1** <font color = red>[2 marks]</font> <br>\n",
    "Calculate the time taken using the features `actual_delivery_time` and `created_at`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBGS4PZJMciZ"
   },
   "outputs": [],
   "source": [
    "# Calculate time taken in minutes\n",
    "df['delivery_time'] = (df['actual_delivery_time'] - df['created_at']).dt.total_seconds() / 60\n",
    "\n",
    "# Drop rows with negative or zero delivery time (data issues)\n",
    "df = df[df['delivery_time'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngUUAf3XOPAP"
   },
   "source": [
    "##### **2.2.2** <font color = red>[3 marks]</font> <br>\n",
    "Extract the hour at which the order was placed and which day of the week it was. Drop the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwA4O5VtNxQW"
   },
   "outputs": [],
   "source": [
    "# Extract the hour and day of week from the 'created_at' timestamp\n",
    "df['order_hour'] = df['created_at'].dt.hour\n",
    "df['order_day_of_week'] = df['created_at'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Create a categorical feature 'isWeekend'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgzSO8wyOTbP"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['created_at', 'actual_delivery_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JJxTsQOFKyl"
   },
   "source": [
    "#### **2.3 Creating training and validation sets** <font color = red>[5 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuyPJMpCFyUL"
   },
   "source": [
    "##### **2.3.1** <font color = red>[2 marks]</font> <br>\n",
    " Define target and input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVyKFLXTFKRE"
   },
   "outputs": [],
   "source": [
    "# Define target variable (y) and features (X)\n",
    "y = df['delivery_time']\n",
    "\n",
    "# Drop the target and non-feature columns to form the feature matrix\n",
    "X = df.drop(columns=['delivery_time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e56iVNqdF3G8"
   },
   "source": [
    "##### **2.3.2** <font color = red>[3 marks]</font> <br>\n",
    " Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0t7XtNDEF6Pu"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "# Perform 80/20 train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQxv96NBAq_y"
   },
   "source": [
    "## **3. Exploratory Data Analysis on Training Data** <font color = red>[20 marks]</font> <br>\n",
    "1. Analyzing the correlation between variables to identify patterns and relationships\n",
    "2. Identifying and addressing outliers to ensure the integrity of the analysis\n",
    "3. Exploring the relationships between variables and examining the distribution of the data for better insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VU1baEcRc1-A"
   },
   "source": [
    "#### **3.1 Feature Distributions** <font color = red> [7 marks]</font> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rj7yFI7VJ_va"
   },
   "outputs": [],
   "source": [
    "# Define numerical and categorical columns for easy EDA and data manipulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWMFLWKpHE-R"
   },
   "source": [
    "##### **3.1.1** <font color = red>[3 marks]</font> <br>\n",
    "Plot distributions for numerical columns in the training set to understand their spread and any skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M0u5G1YR73_"
   },
   "outputs": [],
   "source": [
    "# Plot distributions for all numerical columns\n",
    "# Select numeric features from training data\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Plot distributions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, col in enumerate(numeric_features):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    sns.histplot(X_train[col], bins=30, kde=True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MtpapIvc9rC"
   },
   "source": [
    "##### **3.1.2** <font color = red>[2 marks]</font> <br>\n",
    "Check the distribution of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zr8loNgMLdrm"
   },
   "outputs": [],
   "source": [
    "# Distribution of categorical columns\n",
    "categorical_features = X_train.select_dtypes(include='category').columns\n",
    "\n",
    "# Plot counts for categorical features\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i, col in enumerate(categorical_features):\n",
    "    plt.subplot(1, len(categorical_features), i + 1)\n",
    "    sns.countplot(x=X_train[col])\n",
    "    plt.title(col)\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-9pcLxzJZWf"
   },
   "source": [
    "##### **3.1.3** <font color = red>[2 mark]</font> <br>\n",
    "Visualise the distribution of the target variable to understand its spread and any skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiWe2Bl9R7yL"
   },
   "outputs": [],
   "source": [
    "# Distribution of time_taken\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(y_train, bins=30, kde=True)\n",
    "plt.title(\"Delivery Time Distribution (in minutes)\")\n",
    "plt.xlabel(\"delivery_time\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbxczs61dROZ"
   },
   "source": [
    "#### **3.2 Relationships Between Features** <font color = red>[3 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH81kNkOOvlx"
   },
   "source": [
    "##### **3.2.1** <font color = red>[3 marks]</font> <br>\n",
    "Scatter plots for important numerical and categorical features to observe how they relate to `time_taken`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIBnRHohR799"
   },
   "outputs": [],
   "source": [
    "# Combine X_train and y_train for easy plotting\n",
    "train_combined = X_train.copy()\n",
    "train_combined['time_taken'] = y_train\n",
    "\n",
    "# Important numerical features for scatter plots\n",
    "important_numeric = ['distance', 'total_items', 'subtotal', 'num_distinct_items']\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, col in enumerate(important_numeric):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.scatterplot(x=col, y='time_taken', data=train_combined)\n",
    "    plt.title(f'{col} vs time_taken')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Categorical features (already converted to category dtype)\n",
    "categorical_features = X_train.select_dtypes(include='category').columns\n",
    "\n",
    "# Strip plots for categorical features\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i, col in enumerate(categorical_features):\n",
    "    plt.subplot(1, len(categorical_features), i + 1)\n",
    "    sns.stripplot(x=col, y='time_taken', data=train_combined, jitter=True, alpha=0.4)\n",
    "    plt.title(f'{col} vs time_taken')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiWL3cKowfZd"
   },
   "outputs": [],
   "source": [
    "# Show the distribution of time_taken for different hours\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='order_hour', y='time_taken', data=train_combined)\n",
    "plt.title('Distribution of time_taken by Order Hour')\n",
    "plt.xlabel('Hour of Day (0–23)')\n",
    "plt.ylabel('Delivery Time (minutes)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKg6rBljIJFP"
   },
   "source": [
    "#### **3.3 Correlation Analysis** <font color = red>[5 marks]</font> <br>\n",
    "Check correlations between numerical features to identify which variables are strongly related to `time_taken`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyk00sbYfnc0"
   },
   "source": [
    "##### **3.3.1** <font color = red>[3 marks]</font> <br>\n",
    "Plot a heatmap to display correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxrdHdvKR7vy"
   },
   "outputs": [],
   "source": [
    "# Plot the heatmap of the correlation matrix\n",
    "# Combine training features and target\n",
    "train_corr = X_train.copy()\n",
    "train_corr['time_taken'] = y_train\n",
    "\n",
    "# Select numeric features for correlation\n",
    "numeric_cols = train_corr.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = train_corr[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap - Numerical Features\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yuD3RIwffZE"
   },
   "source": [
    "##### **3.3.2** <font color = red>[2 marks]</font> <br>\n",
    "Drop the columns with weak correlations with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDZN586gH8R_"
   },
   "outputs": [],
   "source": [
    "# Drop 3-5 weakly correlated columns from training dataset\n",
    "# Find correlations with the target\n",
    "target_corr = corr_matrix['time_taken'].drop('time_taken').sort_values()\n",
    "\n",
    "# Display\n",
    "print(\"Correlation with 'time_taken':\")\n",
    "print(target_corr)\n",
    "\n",
    "# Drop features with abs(correlation) < 0.05\n",
    "weak_corr_features = target_corr[abs(target_corr) < 0.05].index.tolist()\n",
    "print(\"\\nDropping features due to weak correlation:\", weak_corr_features)\n",
    "\n",
    "# Drop them from training and validation sets\n",
    "X_train.drop(columns=weak_corr_features, inplace=True)\n",
    "X_val.drop(columns=weak_corr_features, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mZv2rz6lxvc"
   },
   "source": [
    "#### **3.4 Handling the Outliers** <font color = red>[5 marks]</font> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdyAT-OhyH3z"
   },
   "source": [
    "##### **3.4.1** <font color = red>[2 marks]</font> <br>\n",
    "Visualise potential outliers for the target variable and other numerical features using boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow3Mowo4R71T"
   },
   "outputs": [],
   "source": [
    "# Boxplot for time_taken\n",
    "# List of numerical features to visualize (after dropping weak ones)\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(4, 3, i + 1)\n",
    "    sns.boxplot(x=X_train[col])\n",
    "    plt.title(f'Boxplot: {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZCaGBKv_stm"
   },
   "source": [
    "##### **3.4.2** <font color = red>[3 marks]</font> <br>\n",
    "Handle outliers present in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwQ1A_wZ_X_K"
   },
   "outputs": [],
   "source": [
    "# Handle outliers\n",
    "def remove_outliers_iqr(df, cols):\n",
    "    df_clean = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Filter out rows outside the bounds\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "# Combine training features and target for outlier removal\n",
    "train_combined = X_train.copy()\n",
    "train_combined['time_taken'] = y_train\n",
    "\n",
    "# Remove outliers from selected numerical columns\n",
    "outlier_cols = ['distance', 'total_items', 'subtotal', 'num_distinct_items']\n",
    "train_cleaned = remove_outliers_iqr(train_combined, outlier_cols)\n",
    "\n",
    "# Update X_train and y_train\n",
    "X_train = train_cleaned.drop(columns='time_taken')\n",
    "y_train = train_cleaned['time_taken']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0Cd2J-LGWaF"
   },
   "source": [
    "## **4. Exploratory Data Analysis on Validation Data** <font color = red>[optional]</font> <br>\n",
    "Optionally, perform EDA on test data to see if the distribution match with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sN6bG_hTbUE"
   },
   "outputs": [],
   "source": [
    "# Define numerical and categorical columns for easy EDA and data manipulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zq16lr0Q9IG"
   },
   "source": [
    "#### **4.1 Feature Distributions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuoIVgXlQC9y"
   },
   "source": [
    "##### **4.1.1**\n",
    "Plot distributions for numerical columns in the validation set to understand their spread and any skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKgSvKvzG8fv"
   },
   "outputs": [],
   "source": [
    "# Plot distributions for all numerical columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrywBQGWQC9z"
   },
   "source": [
    "##### **4.1.2**\n",
    "Check the distribution of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0CIcl2tHBwp"
   },
   "outputs": [],
   "source": [
    "# Distribution of categorical columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_j74bnlQC9z"
   },
   "source": [
    "##### **4.1.3**\n",
    "Visualise the distribution of the target variable to understand its spread and any skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dGfR8MHGtqm"
   },
   "outputs": [],
   "source": [
    "# Distribution of time_taken\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki2FI7fsHDgK"
   },
   "source": [
    "#### **4.2 Relationships Between Features**\n",
    "Scatter plots for numerical features to observe how they relate to each other, especially to `time_taken`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lzNPoK4HFnZ"
   },
   "outputs": [],
   "source": [
    "# Scatter plot to visualise the relationship between time_taken and other features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8VoM0XfXWko"
   },
   "source": [
    "#### **4.3** Drop the columns with weak correlations with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BnM8w2lXWkp"
   },
   "outputs": [],
   "source": [
    "# Drop the weakly correlated columns from training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReNN4PyM8enl"
   },
   "source": [
    "## **5. Model Building** <font color = red>[15 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l2XfNF6nc8L"
   },
   "source": [
    "#### **Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__fmfT6vQWpd"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCLIKw5pQiA7"
   },
   "source": [
    "#### **5.1 Feature Scaling** <font color = red>[3 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "newEgSyyQiHK"
   },
   "outputs": [],
   "source": [
    "# Apply scaling to the numerical columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXcV5Z_E8tLL"
   },
   "source": [
    "Note that linear regression is agnostic to feature scaling. However, with feature scaling, we get the coefficients to be somewhat on the same scale so that it becomes easier to compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bxip-t3Y1MB"
   },
   "source": [
    "#### **5.2 Build a linear regression model** <font color = red>[5 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7jZciTFtric"
   },
   "source": [
    "You can choose from the libraries *statsmodels* and *scikit-learn* to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMRpgx_iQYM4"
   },
   "outputs": [],
   "source": [
    "# Create/Initialise the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbJVZpMiW8b2"
   },
   "outputs": [],
   "source": [
    "# Train the model using the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCQcJtDbW_dG"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Udw5kE1fXBsR"
   },
   "outputs": [],
   "source": [
    "# Find results for evaluation metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3-HovybcZKR"
   },
   "source": [
    "Note that we have 12 (depending on how you select features) training features. However, not all of them would be useful. Let's say we want to take the most relevant 8 features.\n",
    "\n",
    "We will use Recursive Feature Elimination (RFE) here.\n",
    "\n",
    "For this, you can look at the coefficients / p-values of features from the model summary and perform feature elimination, or you can use the RFE module provided with *scikit-learn*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU8OLQ4bnwdr"
   },
   "source": [
    "#### **5.3 Build the model and fit RFE to select the most important features** <font color = red>[7 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4FZMiX11RyI"
   },
   "source": [
    "For RFE, we will start with all features and use\n",
    "the RFE method to recursively reduce the number of features one-by-one.\n",
    "\n",
    "After analysing the results of these iterations, we select the one that has a good balance between performance and number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ub1HgSwl1eiC"
   },
   "outputs": [],
   "source": [
    "# Loop through the number of features and test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7p-CAQn3wQE"
   },
   "outputs": [],
   "source": [
    "# Build the final model with selected number of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0l_mLL_4OOl"
   },
   "source": [
    "## **6. Results and Inference** <font color = red>[5 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsPGaacJ71mt"
   },
   "source": [
    "#### **6.1 Perform Residual Analysis** <font color = red>[3 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lbj7O8rf7SZS"
   },
   "outputs": [],
   "source": [
    "# Perform residual analysis using plots like residuals vs predicted values, Q-Q plot and residual histogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aq4g9xPsu4T5"
   },
   "source": [
    "[Your inferences here:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2-CiCId7_y9"
   },
   "source": [
    "#### **6.2 Perform Coefficient Analysis** <font color = red>[2 marks]</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2koFJovu-cH"
   },
   "source": [
    "Perform coefficient analysis to find how changes in features affect the target.\n",
    "Also, the features were scaled, so interpret the scaled and unscaled coefficients to understand the impact of feature changes on delivery time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr8EWhg_9QnI"
   },
   "outputs": [],
   "source": [
    "# Compare the scaled vs unscaled features used in the final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ5VcQ2G-SOb"
   },
   "source": [
    "Additionally, we can analyse the effect of a unit change in a feature. In other words, because we have scaled the features, a unit change in the features will not translate directly to the model. Use scaled and unscaled coefficients to find how will a unit change in a feature affect the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMHN7r-x-Lp5"
   },
   "outputs": [],
   "source": [
    "# Analyze the effect of a unit change in a feature, say 'total_items'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFWJ2s9I_Yeo"
   },
   "source": [
    "Note:\n",
    "The coefficients on the original scale might differ greatly in magnitude from the scaled coefficients, but they both describe the same relationships between variables.\n",
    "\n",
    "Interpretation is key: Focus on the direction and magnitude of the coefficients on the original scale to understand the impact of each variable on the response variable in the original units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClCit1tvKIyE"
   },
   "source": [
    "Include conclusions in your report document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mn-wDgoeSiHP"
   },
   "source": [
    "## Subjective Questions <font color = red>[20 marks]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions only in the notebook. Include the visualisations/methodologies/insights/outcomes from all the above steps in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVJSi-Q0Cw_r"
   },
   "source": [
    "#### Subjective Questions based on Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_jiT95xTA6q"
   },
   "source": [
    "##### **Question 1.** <font color = red>[2 marks]</font> <br>\n",
    "\n",
    "Are there any categorical variables in the data? From your analysis of the categorical variables from the dataset, what could you infer about their effect on the dependent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvFQvBy3VM9A"
   },
   "source": [
    "**Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqPxxtWEY3_W"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDSRymTJTHCW"
   },
   "source": [
    "##### **Question 2.** <font color = red>[1 marks]</font> <br>\n",
    "What does `test_size = 0.2` refer to during splitting the data into training and test sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRBCcZvoVx-r"
   },
   "source": [
    "**Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_afbTV8Y5-F"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEVX57VbTJBP"
   },
   "source": [
    "##### **Question 3.** <font color = red>[1 marks]</font> <br>\n",
    "Looking at the heatmap, which one has the highest correlation with the target variable?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewPqz4yLWBzR"
   },
   "source": [
    "**Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLy_-8F5Y69c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg-6E-N-TKyS"
   },
   "source": [
    "##### **Question 4.** <font color = red>[2 marks]</font> <br>\n",
    "What was your approach to detect the outliers? How did you address them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPUDtsRGWLZl"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVyJFcT2Y7U8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvh9CLFnTMhO"
   },
   "source": [
    "##### **Question 5.** <font color = red>[2 marks]</font> <br>\n",
    "Based on the final model, which are the top 3 features significantly affecting the delivery time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-DDpZcCWUun"
   },
   "source": [
    "**Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVCrLjhTY74h"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBLH_lA5C4jy"
   },
   "source": [
    "#### General Subjective Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MJGDVyiTOyr"
   },
   "source": [
    "##### **Question 6.** <font color = red>[3 marks]</font> <br>\n",
    "Explain the linear regression algorithm in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZc1QX8RW_Pa"
   },
   "source": [
    "**Answer:**\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0MCb30NY8UE"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db_7gqf8TQTk"
   },
   "source": [
    "##### **Question 7.** <font color = red>[2 marks]</font> <br>\n",
    "Explain the difference between simple linear regression and multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1jsR8htXD8j"
   },
   "source": [
    "**Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnSGZEltY8ss"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT6ivEEnTSEs"
   },
   "source": [
    "##### **Question 8.** <font color = red>[2 marks]</font> <br>\n",
    "What is the role of the cost function in linear regression, and how is it minimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2PaCL-FXSSn"
   },
   "source": [
    "**Answer:**\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIKB_W0FY9QM"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZIb5hbMCCVY"
   },
   "source": [
    "##### **Question 9.** <font color = red>[2 marks]</font> <br>\n",
    "Explain the difference between overfitting and underfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8kn4c-7CEjP"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PWIs-suCMEr"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os7JPKHwArn7"
   },
   "source": [
    "##### **Question 10.** <font color = red>[3 marks]</font> <br>\n",
    "How do residual plots help in diagnosing a linear regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqxU8GSkAubl"
   },
   "source": [
    "**Answer:**\n",
    ">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MueJxkvUIII3",
    "02uPO8aQfLnn",
    "b22Kzjew3rdM",
    "u1EBPjFc4Qca",
    "-JJxTsQOFKyl",
    "v0Cd2J-LGWaF",
    "fCLIKw5pQiA7",
    "2bxip-t3Y1MB",
    "mn-wDgoeSiHP"
   ],
   "provenance": [
    {
     "file_id": "1qHefVpjLoVZcdohzmYySNZGiPR4wQOFp",
     "timestamp": 1737728120597
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
